spring.application.name=mcp-client
server.port=8223

spring.ai.ollama.base-url=http://localhost:11434
spring.ai.ollama.chat.options.model=llama3.2:latest
spring.ai.ollama.chat.options.temperature=0.7

spring.ai.mcp.client.type=async
spring.ai.mcp.client.sse.connections.server1.url=http://localhost:8123

#mode can have the value of mcp, standard or stream
app.runner.mode=stream

